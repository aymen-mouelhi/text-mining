{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc1 = \"\"\"Python is a 2000 made-for-TV horror movie directed by Richard\n",
    "Clabaugh. The film features several cult favorite actors, including William\n",
    "Zabka of The Karate Kid fame, Wil Wheaton, Casper Van Dien, Jenny McCarthy,\n",
    "Keith Coogan, Robert Englund (best known for his role as Freddy Krueger in the\n",
    "A Nightmare on Elm Street series of films), Dana Barron, David Bowe, and Sean\n",
    "Whalen. The film concerns a genetically engineered snake, a python, that\n",
    "escapes and unleashes itself on a small town. It includes the classic final\n",
    "girl scenario evident in films like Friday the 13th. It was filmed in Los Angeles,\n",
    " California and Malibu, California. Python was followed by two sequels: Python\n",
    " II (2002) and Boa vs. Python (2004), both also made-for-TV films.\"\"\"\n",
    "\n",
    "doc2 = \"\"\" Python is a very nice programming programming programming language\n",
    "language language language used by many researchers, engineers and data scientists.\"\"\"\n",
    "\n",
    "doc3 = \"\"\"The Colt Python is a .357 Magnum caliber revolver formerly\n",
    "manufactured by Colt's Manufacturing Company of Hartford, Connecticut.\n",
    "It is sometimes referred to as a \"Combat Magnum\".[1] It was first introduced\n",
    "in 1955, the same year as Smith &amp; Wesson's M29 .44 Magnum. The now discontinued\n",
    "Colt Python targeted the premium revolver market segment. Some firearm\n",
    "collectors and writers such as Jeff Cooper, Ian V. Hogg, Chuck Hawks, Leroy\n",
    "Thompson, Renee Smeets and Martin Dougherty have described the Python as the\n",
    "finest production revolver ever made.\"\"\"\n",
    "\n",
    "\n",
    "collection = [doc1, doc2, doc3]\n",
    "collection =[x.split(' ') for x in collection]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf(word, doc):\n",
    "\n",
    "def idf(word, collection):\n",
    "\n",
    "\n",
    "def tfidf(word, doc, collection):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print most 4 top important words per doc\n",
    "for i,doc in enumerate(collection):\n",
    "    important=[]\n",
    "    for word in set(doc):\n",
    "        \n",
    "            important.append((word,tfidf(word,doc,collection)))\n",
    "    important=sorted(important,key=lambda x:x[1])[::-1]\n",
    "    print important[0:4]\n",
    "    print\"------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#NLTK is a library fro natural language processing related tasks\n",
    "#it has various stemmers\n",
    "from nltk.stem.snowball import SnowballStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = [\"Euler is the father of graph theory\",\n",
    "             \"Graph theory studies the properties of graphs\",\n",
    "             \"Bioinformatics studies the application of efficient algorithms in biological problems\",\n",
    "             \"DNA sequences are very complex biological structures\",\n",
    "             \"Genes are parts of a DNA sequence\",\n",
    "             \"This is Euler bioinformatics sequence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tf-idf vectorizer does automaic tf-idf calculation on a list of strings (documents)\n",
    "#it maintains the list of terms found\n",
    "#we can also find the idf values of specific words\n",
    "#compute similarity among documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we can also use tf-idf to retrieve documents with queries based on the similarity of the query to all docs\n",
    "documents2 = [\"Euler is the father of graph theory\",\n",
    "             \"Graph theory studies the properties of graphs\",\n",
    "             \"Bioinformatics studies the application of efficient algorithms in biological problems\",\n",
    "             \"DNA sequences are very complex structures\",\n",
    "             \"Genes are parts of a DNA sequence\",\n",
    "             \"Run to the hills, run for your lives\",\n",
    "             \"The lonenliness of the long distance runner\",\n",
    "             \" Heaven can wait til another day\",\n",
    "             \"Road runner and coyote is my favorite cartoon\",\n",
    "             ]\n",
    "              #\"Heaven can wait\" # this is our query\n",
    "query=\" heaven can wait\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = [\"Euler is the father of graph theory\",\n",
    "             \"Graph theory studies the properties of graphs\",\n",
    "             \"Graph theory is cool!\",\n",
    "             \"DNA sequences are very complex biological structures\",\n",
    "             \"Genes are biological structures that are parts of a DNA sequence\",\n",
    "             \"Genes are very important biological structures\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Latent semantic analysis: project document to the clustetr (concepts) they belong to\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "\n",
    "#we keep 2 eigen vecors from the term to term similarity part (V) \n",
    "#which will represent two clsters/topics in our collection\n",
    "#after, we project the data on two these concepts (eigenvectors) to replace words with their projections\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "#plot the projected documents -we know that there are two clusters by looking at the documents\n",
    "#and we see the same in the new projection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "TF-IDF as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lets use the previous in a classification task\n",
    "#load data\n",
    "data=pd.read_csv('movie_reviews.csv',header=None)\n",
    "data.columns=['text','label']\n",
    "# Part 2: data preprocessing\n",
    "############\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train and predict with  BernouliNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
